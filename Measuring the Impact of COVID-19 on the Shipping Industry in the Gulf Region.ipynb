{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the Impact of COVID-19 on the Shipping Industry in the Gulf Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In social commerce, the role of shipping companies is considered essential to provide good customer experience. The objective of this study is to measure the impact of COVID-19 pandemic on social commerce costumers in the Gulf region. The study is focused on published information by costumers on international and domestic shipping companies through Twitter. We have analysed a total of 10,006 Arabic and English Tweets that were posted during the months of June and July 2020 to conduct our study. After performing sentiment analysis on these Tweets, the results show that even though more people switched to social commerce businesses, the costumer experience has dropped drastically due to delayed shipments in the Gulf region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, this notebook was produced to explore, get, and analyze Tweets using Twitter API. We started by getting Tweets for the GCC region as a whole, and then filtered down our research into each of its countries. Please note that several parts of the code written here was inspired from our course '99-520: Data Analysis for Social Commerce Platforms in the Gulf during COVID-19' in Carnegie Mellon University Qatar. All of this information can be found below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Installing libraries and helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and foremost, we have to download the python libraries and write the helper functions needed to produce the data; and they are as follows:\n",
    "#### 1) Tweepy: \n",
    "Twitter API used to gather Tweets from Twitter\n",
    "#### 2) Pandas, matplotlib, and seaborn: \n",
    "Data visualization libraries\n",
    "#### 3) Textblob, networkx, and nltk: \n",
    "Data analysis libraries\n",
    "#### 4) Others: \n",
    "libraries used to assist with the analysis step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\ashaa\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\ashaa\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\ashaa\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ashaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "import tweepy as tw\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "import csv\n",
    "import urllib\n",
    "from pprint import pprint\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "#helper function used to remove the URL from a given string. This is helpful as the Tweets we get from the Twitter API often\n",
    "#contains the url of the Tweet, which could hinder the accuracy of our sentiment analysis tools.\n",
    "#Requires: a string\n",
    "#Ensures: The same txt string with url's removed.\n",
    "def remove_url(txt):\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Getting authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are getting information from Twitter, authentication matters because it enables Twitter to keep their networks secure by permitting only authenticated users (or processes) to access its protected resources. For privacy reasons, we have commented out our key and access tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consumer_key = 'Your consumer key here'\n",
    "# consumer_secret = 'Your consumer secret here'\n",
    "# access_token = 'Your access token here'\n",
    "# access_secret = 'Your access secret here'\n",
    "consumer_key = 'W5hpNRkG3lGflwXju5nGhC6yS'\n",
    "consumer_secret = 'QrGCY6LvrlRY79KKcLs6LofX7vVEyKVCPO29uQe8ynxfC5MNCM'\n",
    "access_token = '1279943091059900416-1XYRUDEbxgGqW5oFVwpJjXX2KNswzM'\n",
    "access_secret = 'r2MwwdqgBUvOGU8xIkWDuCaxBiNKf8SvauRXvN4FLPxWK'\n",
    "\n",
    "try:\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit=True)\n",
    "    \n",
    "except:\n",
    "    print(\"Error: Authentication Failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aramex related Tweets in the GCC region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Aramex Shipping in GCC countries - English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = \"\"\"AramexUAE OR AramexQatar OR AramexKwi OR AramexQa OR Aramex_KSA OR UPS_Kuwait\"\"\"\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode = 'extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"aramex_gcc_en.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "#general information saved for analysis\n",
    "aramex_gcc_en = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"thanks for reaching out\" not in filtered_text):\n",
    "        aramex_gcc_en.append(tweet.full_text)\n",
    "        counter += 1\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "        \n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Aramex shipping in GCC countries - Arabic Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = \"\"\"AramexUAE OR AramexQatar OR AramexKwi OR AramexQa OR AramexQatar OR Aramex_KSA\"\"\"\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode = 'extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#analysis\n",
    "aramex_gcc_ar = []\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"aramex_gcc_ar.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "    \n",
    "    text = tweet.full_text\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        if (\"مرحبا\" not in text):\n",
    "            aramex_gcc_ar.append(text)\n",
    "            csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "            \n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) The usage of Shop and Ship in the GCC countries - English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = \"#shopandship OR shopandship OR @shopandship\"\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#general information saved for analysis\n",
    "shopANDship_gcc_en = []\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"shopANDship_gcc_en.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "# Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"thanks for reaching out\" not in tweet.full_text):\n",
    "        counter += 1\n",
    "        shopANDship_gcc_en.append(tweet.full_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) The usage of Shop and Ship in the GCC countries - Arabic Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#shopandship OR shopandship OR @shopandship -filter:retweets\n"
     ]
    }
   ],
   "source": [
    "#Search words and Date\n",
    "search_words = \"#shopandship OR shopandship OR @shopandship\"\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "print(search_words)\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items()\n",
    "\n",
    "#general information saved for analysis\n",
    "shopANDship_gcc_ar = []\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "\n",
    "csvFile = open(\"shopANDship_gcc_ar.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "    text = tweet.full_text\n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        if (\"مرحبا\" not in text):\n",
    "            shopANDship_gcc_ar.append(text)\n",
    "            csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "csvFile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPS related Tweets in the GCC region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) The usage of UPS shipping service in the GCC region - English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = \"UPS_UAE OR UPSQatar OR UPSKwi OR UPSQa OR UPS_KSA OR UPS_Kuwait\"\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode = 'extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"ups_gcc_en.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "#general information saved for analysis\n",
    "ups_gcc_en = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"thanks for reaching out\" not in filtered_text):\n",
    "        aramex_gcc_en.append(tweet.full_text)\n",
    "        counter += 1\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "        \n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) The usage of UPS shipping service in the GCC region - Arabic Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = \"UPS_UAE OR UPSQatar OR UPSKwi OR UPSQa OR UPS_KSA OR UPS_Kuwait\"\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode = 'extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"ups_gcc_ar.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "#general information saved for analysis\n",
    "ups_gcc_ar = []\n",
    "\n",
    "for tweet in tweets:\n",
    "\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "    text = tweet.full_text\n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        if (\"مرحبا\" not in text):\n",
    "            shopANDship_gcc_ar.append(text)\n",
    "            csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHL related Tweets in the GCC region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) The usage of DHL shipping service in the GCC region - English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = \"DHL_UAE OR DHLQatar OR DHLKwi OR DHLQa OR DHL_KSA OR DHL_Kuwait\"\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode = 'extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"dhl_gcc_en.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "#general information saved for analysis\n",
    "dhl_gcc_en = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"thanks for reaching out\" not in filtered_text):\n",
    "        aramex_gcc_en.append(tweet.full_text)\n",
    "        counter += 1\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "        \n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) The usage of DHL shipping service in the GCC region - Arabic Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = \"DHL_UAE OR DHLQatar OR DHLKwi OR DHLQa OR DHL_KSA OR DHL_Kuwait\"\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode = 'extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"dhl_gcc_ar.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "#general information saved for analysis\n",
    "dhl_gcc_ar = []\n",
    "\n",
    "for tweet in tweets:\n",
    "\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "    text = tweet.full_text\n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        if (\"مرحبا\" not in text):\n",
    "            shopANDship_gcc_ar.append(text)\n",
    "            csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of Tweets available for DHL and UPS shipping companies is signficantly lower than for Aramex (0.2:99.8), we decided to further our analysis with Aramex shipping company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generated Tweets for specific to every GCC country to be able to analyze each of them more specifically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Shipping in Qatar - English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = '@Qatar_post OR @MOCIQatar'\n",
    "\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#general information saved for analysis\n",
    "shipping_qatar_en = []\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"shipping_qatar_en.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "    replies = []\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"thanks for reaching out\" not in filtered_text):\n",
    "        counter += 1\n",
    "        shipping_qatar_en.append(tweet.full_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "search_words = \"@shopandship AND qatar\"\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"general inquiries\" not in filtered_text):\n",
    "        counter += 1\n",
    "        shipping_qatar_en.append(filtered_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Shipping in Qatar - Arabic Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = '@Qatar_post OR @MOCIQatar'\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items()\n",
    "\n",
    "#general information saved for analysis\n",
    "shipping_qatar_ar = []\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "\n",
    "csvFile = open(\"shipping_qatar_ar.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "\n",
    "    text = tweet.full_text\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        shipping_qatar_ar.append(text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "        \n",
    "search_words = \"@shopandship AND qatar\"\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "\n",
    "    text = tweet.full_text\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        shipping_qatar_ar.append(text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Shipping in UAE - English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'full_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-236762ea9b0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"general inquiries\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiltered_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0maramex_UAE_en\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mcsvWriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_created\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'full_text'"
     ]
    }
   ],
   "source": [
    "#Search words and Date\n",
    "search_words = 'aramex AND Dubai'\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#general information saved for analysis\n",
    "aramex_UAE_en = []\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"aramex_UAE_en.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "    replies = []\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"thanks for reaching out\" not in filtered_text):\n",
    "        counter += 1\n",
    "        aramex_UAE_en.append(tweet.full_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "        \n",
    "search_words = \"@shopandship AND dubai\"\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    replies = []\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"general inquiries\" not in filtered_text):\n",
    "        aramex_UAE_en.append(filtered_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "search_words = \"@shopandship AND UAE\"\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    replies = []\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"general inquiries\" not in filtered_text):\n",
    "        aramex_UAE_en.append(text.full_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Shipping in UAE - Arabic Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = '#aramex and UAE'\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items()\n",
    "\n",
    "#general information saved for analysis\n",
    "aramex_UAE_ar = []\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "\n",
    "csvFile = open(\"aramex_UAE_ar.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "\n",
    "    text = tweet.full_text\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        aramex_UAE_ar.append(text)\n",
    "        \n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "        \n",
    "search_words = \"@shopandship AND dubai\"\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "\n",
    "    text = tweet.full_text\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        aramex_UAE_ar.append(text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "\n",
    "search_words = \"@shopandship AND UAE\"\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "\n",
    "    text = tweet.full_text\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        aramex_UAE_ar.append(text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Shipping in Kuwait - English Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = '@AramexKWI'\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#general information saved for analysis\n",
    "aramex_kuwait_en = []\n",
    "\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"aramex_kuwait_en.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "    replies = []\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"general inquiries\" not in filtered_text):\n",
    "        aramex_kuwait_en.append(filtered_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "search_words = '@UPS AND kuwait'\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    replies = []\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"general inquiries\" not in filtered_text):\n",
    "        aramex_kuwait_en.append(filtered_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "search_words = '@Aramex AND kuwait'\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    replies = []\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"general inquiries\" not in filtered_text):\n",
    "        aramex_kuwait_en.append(filtered_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Shipping in Kuwait - Arabic Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = '@AramexKWI'\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#general information saved for analysis\n",
    "aramex_kuwait_ar = []\n",
    "    \n",
    "# Saving the tweets in a csv file:\n",
    "csvFile = open(\"aramex_kuwait_ar.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "# Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "\n",
    "    text = tweet.full_text\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        aramex_kuwait_ar.append(text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "search_words = '@UPS AND kuwait'\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "\n",
    "    text = tweet.full_text\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        aramex_kuwait_ar.append(text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "\n",
    "search_words = '@Aramex AND kuwait'\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "\n",
    "    text = tweet.full_text\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        aramex_kuwait_ar.append(text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Shipping in KSA - English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = '@Aramex_KSA'\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "print(search_words)\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#general information saved for analysis\n",
    "aramex_KSA_en = []\n",
    "    \n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"aramex_KSA_en.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "\n",
    "for tweet in tweets:\n",
    "    replies = []\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"general inquiries\" not in filtered_text):\n",
    "        aramex_KSA_en.append(tweet.full_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "search_words = '@Aramex AND KSA'\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    replies = []\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"general inquiries\" not in filtered_text):\n",
    "        aramex_KSA_en.append(tweet.full_text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Shipping in KSA - Arabic Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = '@Aramex_KSA'\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"aramex_KSA_ar.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "#general information saved for analysis\n",
    "aramex_KSA_ar = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "\n",
    "    text = tweet.full_text\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        aramex_KSA_ar.append(text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "\n",
    "search_words = '@Aramex AND KSA'\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"ar\",\n",
    "                   tweet_mode='extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text.encode('utf-8')\n",
    "\n",
    "    text = tweet.full_text\n",
    "    \n",
    "    screen_user = tweet.user.screen_name.encode('utf-8')\n",
    "    \n",
    "    location = tweet.user.location.encode('utf-8')\n",
    "\n",
    "    if (\"شكراً لتواصلك معنا\" not in text):\n",
    "        aramex_KSA_ar.append(text)\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And by that, we have gathered Tweets the GCC region as a whole for each one of its country and saved them in a csv file for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to get a general idea about the number of Tweets we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"aramex_KSA_en tweets: \", len(aramex_KSA_en))\n",
    "print(\"aramex_KSA_ar tweets: \", len(aramex_KSA_ar))\n",
    "\n",
    "print(\"aramex_kuwait_en tweets: \", len(aramex_kuwait_en))\n",
    "print(\"aramex_kuwait_ar tweets: \", len(aramex_kuwait_ar))\n",
    "\n",
    "print(\"shipping_qatar_en tweets: \", len(shipping_qatar_en))\n",
    "print(\"shipping_qatar_ar tweets: \", len(shipping_qatar_ar))\n",
    "\n",
    "print(\"shopANDship_gcc_en tweets: \", len(shopANDship_gcc_en))\n",
    "print(\"shopANDship_gcc_ar tweets: \", len(shopANDship_gcc_ar))\n",
    "\n",
    "print(\"aramex_gcc_en tweets: \", len(aramex_gcc_en))\n",
    "print(\"aramex_gcc_ar tweets: \", len(aramex_gcc_ar))\n",
    "\n",
    "print(\"aramex_UAE_en tweets: \", len(aramex_UAE_en))\n",
    "print(\"aramex_UAE_ar tweets: \", len(aramex_UAE_ar))\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "for s in aramex_gcc_en:\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "for s in aramex_gcc_ar:\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))    \n",
    "\n",
    "    \n",
    "arabic_length = len(aramex_KSA_ar) + len(aramex_kuwait_ar) + len(shipping_qatar_ar) + len(shopANDship_gcc_ar)\n",
    "arabic_length += len(aramex_gcc_ar) + len(aramex_UAE_ar)\n",
    "\n",
    "english_length = len(aramex_KSA_en) + len(aramex_kuwait_en) + len(shipping_qatar_en) + len(shopANDship_gcc_en)\n",
    "english_length += len(aramex_gcc_en) + len(aramex_UAE_en)\n",
    "                        \n",
    "print(\"Number of Arabic Tweets: \", arabic_length)\n",
    "print(\"Number of English Tweets: \", english_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer feedback in the GCC region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer our research question, the first step we have to do is get a general idea about the consumers' feedback on shipping services in the GCC region as a whole. Since we barely had any data for UPS and DHL shipping companies, we performed our analysis on Aramex only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_en = [tweet.lower().split() for tweet in aramex_gcc_en]\n",
    "words_ar = [tweet.lower().split() for tweet in aramex_gcc_ar]\n",
    "\n",
    "stopwords_ar = set(stopwords.words('arabic'))\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "\n",
    "tweets_en = [[word for word in tweet_words if not word in stopwords_en and not \"@aramex\" in word]\n",
    "              for tweet_words in words_en]\n",
    "   \n",
    "tweets_ar = [[word for word in tweet_words if not word in stopwords_ar and not \"@aramex\" in word]\n",
    "              for tweet_words in words_ar]\n",
    "\n",
    "\n",
    "all_words_en = list(itertools.chain(*tweets_en))\n",
    "all_words_ar = list(itertools.chain(*tweets_ar))\n",
    "\n",
    "\n",
    "counts_en = collections.Counter(all_words_en)\n",
    "counts_ar = collections.Counter(all_words_ar)\n",
    "\n",
    "\n",
    "\n",
    "wc = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords_en, \n",
    "                min_font_size = 10).generate(\" \".join(all_words_en)) \n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "\n",
    "plt.savefig('aramex_gcc_en.png')\n",
    "\n",
    "# wc = WordCloud(width = 800, height = 800, \n",
    "#                 background_color ='white', \n",
    "#                 stopwords = stopwords_en, \n",
    "#                 min_font_size = 10).generate(\" \".join(all_words_ar)) \n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.imshow(wc)\n",
    "\n",
    "# plt.savefig('aramex_gcc_ar.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However this was not enough, we had to also get the polarity of these Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = aramex_gcc_en + aramex_gcc_ar + shopANDship_gcc_en + shopANDship_gcc_ar  + aramex_KSA_en + aramex_KSA_ar\n",
    "all_tweets += aramex_kuwait_en + aramex_kuwait_ar + shipping_qatar_en + shipping_qatar_ar + aramex_UAE_en + aramex_UAE_ar\n",
    "\n",
    "sentiment_objects = [TextBlob(tweet) for tweet in all_tweets]\n",
    "\n",
    "all_sentiment = [tweet.sentiment.polarity for tweet in sentiment_objects]\n",
    "pos_counter = 0\n",
    "neg_counter = 0\n",
    "neu_counter = 0\n",
    "\n",
    "print(len(all_tweets))\n",
    "\n",
    "sentiment_values = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_objects]\n",
    "print(sentiment_values[0])\n",
    "# Create dataframe containing the polarity value and tweet text\n",
    "\n",
    "sentiment_df = pd.DataFrame(sentiment_values, columns=[\"polarity\", \"tweet\"])\n",
    "sentiment_df = sentiment_df[sentiment_df.polarity != 0]\n",
    "\n",
    "x = sentiment_df['polarity'].values # array with polarity only\n",
    "\n",
    "sns.distplot(x, color = 'red');\n",
    "\n",
    "# Calculating the mean\n",
    "mean = sentiment_df['polarity'].mean()\n",
    "\n",
    "#ploting the mean\n",
    "plt.axvline(mean, 0,1, color = 'blue')\n",
    "\n",
    "plt.title(\"Sentiment analysis for shipments in the GCC countries\")\n",
    "plt.ylabel(\"Frequency (x100)\")\n",
    "plt.xlabel(\"Polarity\")\n",
    "\n",
    "      \n",
    "plt.savefig('Sentiment analysis for shipments in the GCC countries.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further understand the nature of our tweets, we looked at the co-occuring words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of lists containing bigrams in tweets\n",
    "terms_bigram = [list(bigrams(tweet)) for tweet in tweets_en]\n",
    "\n",
    "# Flatten list of bigrams in clean tweets\n",
    "bigrams = list(itertools.chain(*terms_bigram))\n",
    "\n",
    "# Create counter of words in clean bigrams\n",
    "bigram_counts = collections.Counter(bigrams)\n",
    "\n",
    "bigram_df = pd.DataFrame(bigram_counts.most_common(15),\n",
    "                             columns=['bigram', 'count'])\n",
    "\n",
    "# Create dictionary of bigrams and their counts\n",
    "d = bigram_df.set_index('bigram').T.to_dict('records')\n",
    "# Create network plot \n",
    "G = nx.Graph()\n",
    "\n",
    "# Create connections between nodes\n",
    "for k, v in d[0].items():\n",
    "    G.add_edge(k[0], k[1], weight=(v * 5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "pos = nx.spring_layout(G, k=4)\n",
    "\n",
    "# Plot networks\n",
    "nx.draw_networkx(G, pos,\n",
    "                 font_size=10,\n",
    "                 width=2,\n",
    "                 edge_color='grey',\n",
    "                 node_color='gray',\n",
    "                 with_labels = False,\n",
    "                 ax=ax)\n",
    "\n",
    "# Create offset labels\n",
    "for key, value in pos.items():\n",
    "    x, y = value[0]+.135, value[1]+.045\n",
    "    ax.text(x, y,\n",
    "            s=key,\n",
    "            bbox=dict(facecolor='black', alpha=0.25),\n",
    "            horizontalalignment='center', fontsize=10)\n",
    "\n",
    "plt.title(\"Most occuring bigrams in the English tweets\")\n",
    "\n",
    "plt.savefig('bigram_gcc.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer feedback in Qatar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we started by generating a wordcloud that represents the nature of Tweets here in Qatar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_shipping_qatar_en = [tweet.lower().split() for tweet in shipping_qatar_en]\n",
    "# words_shipping_qatar_ar = [tweet.lower().split() for tweet in aramex_gcc_ar]\n",
    "\n",
    "tweets_nsw_en = [[word for word in tweet_words if not word in stopwords_en and not \"@aramex\" in word]\n",
    "              for tweet_words in words_shipping_qatar_en]\n",
    "\n",
    "# tweets_nsw_ar = [[word for word in tweet_words if not word in stopwords_ar and not \"@aramex\" in word]\n",
    "#               for tweet_words in words_aramix_gcc_ar]\n",
    "\n",
    "all_words_nsw_en = list(itertools.chain(*tweets_nsw_en))\n",
    "# all_words_nsw_ar = list(itertools.chain(*tweets_nsw_ar))\n",
    "\n",
    "\n",
    "counts_nsw_en = collections.Counter(all_words_nsw_en)\n",
    "# counts_nsw_ar = collections.Counter(all_words_nsw_ar)\n",
    "\n",
    "# print(type(counts_nsw_en))\n",
    "\n",
    "# counts_nsw_ar.most_common(20)\n",
    "\n",
    "# from wordcloud import WordCloud\n",
    "\n",
    "wc = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords_en, \n",
    "                min_font_size = 10).generate(\" \".join(all_words_nsw_en)) \n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "\n",
    "plt.savefig('qatar_shipping_en.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then analyzed the polarity of these Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = shipping_qatar_en + shipping_qatar_ar\n",
    "sentiment_objects = [TextBlob(tweet) for tweet in all_tweets]\n",
    "\n",
    "sentiment_values = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_objects]\n",
    "print(sentiment_values[0])\n",
    "# Create dataframe containing the polarity value and tweet text\n",
    "\n",
    "sentiment_df = pd.DataFrame(sentiment_values, columns=[\"polarity\", \"tweet\"])\n",
    "\n",
    "\n",
    "# Remove polarity values equal to zero\n",
    "sentiment_df = sentiment_df[sentiment_df.polarity != 0]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot histogram with break at zero\n",
    "sentiment_df.hist(bins=[-1, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1],\n",
    "             ax=ax,\n",
    "             color=\"rosybrown\")\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Sentiment analysis for shipments in Qatar\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Polarity\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('Sentiment analysis for shipments in Qatar.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for English tweets only in Qatar\n",
    "all_tweets = shipping_qatar_en\n",
    "sentiment_objects = [TextBlob(tweet) for tweet in all_tweets]\n",
    "\n",
    "# sentiment_objects[2].polarity, sentiment_objects[2].subjectivity , sentiment_objects[2]\n",
    "all_sentiment = [tweet.sentiment.polarity for tweet in sentiment_objects]\n",
    "\n",
    "pos = 0\n",
    "neg = 0\n",
    "neut = 0\n",
    "\n",
    "for i in range(len(sentiment_objects)):\n",
    "    if sentiment_objects[i].polarity > 0:\n",
    "        pos += 1\n",
    "    elif sentiment_objects[i].polarity < 0:\n",
    "        neg += 1\n",
    "    else:\n",
    "        neut += 1 \n",
    "total = pos + neg + neut\n",
    "s = [100 * (pos/total), 100 * (neg/total), 100 * (neut/total)]\n",
    "\n",
    "sentiment_df = pd.DataFrame(s, columns=[\"polarity\"])\n",
    "\n",
    "\n",
    "\n",
    "labels = 'positive', 'negative', 'neutral'\n",
    "sizes = s\n",
    "explode = (0.1, 0.1, 0.1)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "\n",
    "plt.title(\"Qatari's feedback when using Aramex - English tweets\")\n",
    "\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.savefig(\"Qatari's feedback when using Aramex - English tweets.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Arabic Tweets only in Qatar\n",
    "all_tweets = shipping_qatar_ar\n",
    "sentiment_objects = [TextBlob(tweet) for tweet in all_tweets]\n",
    "\n",
    "all_sentiment = [tweet.sentiment.polarity for tweet in sentiment_objects]\n",
    "\n",
    "pos = 0\n",
    "neg = 0\n",
    "neut = 0\n",
    "\n",
    "for i in range(len(sentiment_objects)):\n",
    "    if sentiment_objects[i].polarity > 0:\n",
    "        pos += 1\n",
    "    elif sentiment_objects[i].polarity < 0:\n",
    "        neg += 1\n",
    "    else:\n",
    "        neut += 1 \n",
    "total = pos + neg\n",
    "s = [100 * (pos/total), 100 * (pos/neg)]\n",
    "\n",
    "sentiment_df = pd.DataFrame(s, columns=[\"polarity\"])\n",
    "\n",
    "labels = 'positive', 'negative'\n",
    "sizes = s\n",
    "explode = (0.1, 0.1)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "\n",
    "plt.title(\"Qatari's feedback when using Aramex - Arabic tweets\")\n",
    "\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.savefig(\"Qatari's feedback when using Aramex - Arabic tweets.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer feedback in KSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KSA\n",
    "all_tweets = aramex_KSA_en + aramex_KSA_ar\n",
    "sentiment_objects = [TextBlob(tweet) for tweet in all_tweets]\n",
    "\n",
    "sentiment_values = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_objects]\n",
    "\n",
    "sentiment_df = pd.DataFrame(sentiment_values, columns=[\"polarity\", \"tweet\"])\n",
    "\n",
    "\n",
    "# Remove polarity values equal to zero\n",
    "sentiment_df = sentiment_df[sentiment_df.polarity != 0]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot histogram with break at zero\n",
    "sentiment_df.hist(bins=[-1, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1],\n",
    "             ax=ax,\n",
    "             color=\"lightpink\")\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Sentiment analysis for shipments in KSA\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Polarity\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('Sentiment analysis for shipments in KSA.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer feedback in UAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UAE\n",
    "all_tweets = aramex_UAE_en + aramex_UAE_ar\n",
    "sentiment_objects = [TextBlob(tweet) for tweet in all_tweets]\n",
    "\n",
    "sentiment_values = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_objects]\n",
    "\n",
    "sentiment_df = pd.DataFrame(sentiment_values, columns=[\"polarity\", \"tweet\"])\n",
    "\n",
    "\n",
    "# Remove polarity values equal to zero\n",
    "sentiment_df = sentiment_df[sentiment_df.polarity != 0]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot histogram with break at zero\n",
    "sentiment_df.hist(bins=[-1, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1],\n",
    "             ax=ax,\n",
    "             color=\"rosybrown\")\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Sentiment analysis for shipments in UAE\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Polarity\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('Sentiment analysis for shipments in UAE.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer feedback in Kuwait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kuwait\n",
    "all_tweets = aramex_kuwait_en + aramex_kuwait_ar\n",
    "sentiment_objects = [TextBlob(tweet) for tweet in all_tweets]\n",
    "\n",
    "sentiment_values = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_objects]\n",
    "\n",
    "sentiment_df = pd.DataFrame(sentiment_values, columns=[\"polarity\", \"tweet\"])\n",
    "\n",
    "# Remove polarity values equal to zero\n",
    "sentiment_df = sentiment_df[sentiment_df.polarity != 0]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot histogram with break at zero\n",
    "sentiment_df.hist(bins=[-1, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1],\n",
    "             ax=ax,\n",
    "             color=\"moccasin\")\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Sentiment analysis for shipments in Kuwait\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Polarity\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('Sentiment analysis for shipments in Kuwait.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And by that, we conclude the data we analyzed and gathered for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
